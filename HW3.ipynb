{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 3\n",
    "submitted by: Amin Shojaeighadikolaei   Mar-24-2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Question: Implement a Multilayer Perceptron model with the Backpropagation algorithm using only NumPy and no other module.\n",
    "\n",
    "- data is the same as in Homework 2\n",
    "- 3 layers, 800 neurons in each hidden layer, ReLU activations and softmax in the last layer\n",
    "- batchsize=30 and shuffle before each epoch\n",
    "- test as in Homework 2 and show the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we want to design a Neural Network with Backpropagation algorithm in which we just using Numpy module. Based on the question, the Network is 3 layer which means has 2 hidden layer each has 800 neurons. The dataset is mnist148.nbz which is consist of 300 sample of handwriting images and 3 image for test. In hence, the input size is (300*28*28) , output size is (300*1) and test size is (3*28*28). At first I want to import the libraries and then I will write the functions for Neural Network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ANN:\n",
    "    def __init__(self, layers_size):\n",
    "        self.layers_size = layers_size\n",
    "        self.parameters = {}\n",
    "        self.L = len(self.layers_size)\n",
    "        self.n = 0\n",
    "        self.costs = []\n",
    "        self.once = True\n",
    " \n",
    " \n",
    "    def activation_function(self,type, x , derivation):\n",
    "        if type == \"Sigmoid\" :\n",
    "            if derivation == False:\n",
    "                return 1 / (1 + np.exp(-x))\n",
    "            else:\n",
    "                s = 1 / (1 + np.exp(-x))\n",
    "                return s * (1 - s)\n",
    "\n",
    "        if type == \"ReLU\":\n",
    "            if derivation == False:\n",
    "                return x * (x > 0)\n",
    "            else:\n",
    "                return 1. * (x > 0)\n",
    "\n",
    "        if type == \"Softmax\":\n",
    "            expZ = np.exp(x - np.max(x))\n",
    "            return expZ / expZ.sum(axis=0, keepdims=True)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "    def initialize_parameters(self):\n",
    "        np.random.seed(1)\n",
    " \n",
    "        for l in range(1, len(self.layers_size)):\n",
    "            self.parameters[\"W\" + str(l)] = np.random.randn(self.layers_size[l], self.layers_size[l - 1]) / np.sqrt(\n",
    "                self.layers_size[l - 1])\n",
    "            self.parameters[\"b\" + str(l)] = np.zeros((self.layers_size[l], 1))\n",
    " \n",
    "    def forward(self, X):\n",
    "        store = {}\n",
    " \n",
    "        A = X.T\n",
    "        for l in range(self.L - 1):\n",
    "            Z = self.parameters[\"W\" + str(l + 1)].dot(A) + self.parameters[\"b\" + str(l + 1)]\n",
    "            A = self.activation_function(\"ReLU\" ,Z, derivation=False)\n",
    "            store[\"A\" + str(l + 1)] = A\n",
    "            store[\"W\" + str(l + 1)] = self.parameters[\"W\" + str(l + 1)]\n",
    "            store[\"Z\" + str(l + 1)] = Z\n",
    " \n",
    "        Z = self.parameters[\"W\" + str(self.L)].dot(A) + self.parameters[\"b\" + str(self.L)]\n",
    "        A = self.activation_function( \"Softmax\",Z , derivation= False)\n",
    "        store[\"A\" + str(self.L)] = A\n",
    "        store[\"W\" + str(self.L)] = self.parameters[\"W\" + str(self.L)]\n",
    "        store[\"Z\" + str(self.L)] = Z\n",
    " \n",
    "        return A, store\n",
    " \n",
    "   \n",
    " \n",
    "    def backward(self, X, Y, store):\n",
    " \n",
    "        derivatives = {}\n",
    " \n",
    "        store[\"A0\"] = X.T\n",
    " \n",
    "        A = store[\"A\" + str(self.L)]\n",
    "        dZ = A - Y.T\n",
    " \n",
    "        dW = dZ.dot(store[\"A\" + str(self.L - 1)].T) / self.n\n",
    "        db = np.sum(dZ, axis=1, keepdims=True) / self.n\n",
    "        dAPrev = store[\"W\" + str(self.L)].T.dot(dZ)\n",
    " \n",
    "        derivatives[\"dW\" + str(self.L)] = dW\n",
    "        derivatives[\"db\" + str(self.L)] = db\n",
    " \n",
    "        for l in range(self.L - 1, 0, -1):\n",
    "            dZ = dAPrev * self.activation_function( \"ReLU\", store[\"Z\" + str(l)] , derivation = True)\n",
    "            dW = 1. / self.n * dZ.dot(store[\"A\" + str(l - 1)].T)\n",
    "            db = 1. / self.n * np.sum(dZ, axis=1, keepdims=True)\n",
    "            if l > 1:\n",
    "                dAPrev = store[\"W\" + str(l)].T.dot(dZ)\n",
    " \n",
    "            derivatives[\"dW\" + str(l)] = dW\n",
    "            derivatives[\"db\" + str(l)] = db\n",
    " \n",
    "        return derivatives\n",
    " \n",
    "    def train(self, X, Y, learning_rate=0.01, n_iterations=1):\n",
    "        np.random.seed(1)\n",
    " \n",
    "        self.n = X.shape[0]\n",
    "        \n",
    "        if self.once == True :\n",
    "            self.layers_size.insert(0, X.shape[1])\n",
    "            self.once = False\n",
    " \n",
    "        self.initialize_parameters()\n",
    "        for loop in range(n_iterations):\n",
    "            A, store = self.forward(X)\n",
    "            cost = -np.mean(Y * np.log(A.T+ 1e-8))\n",
    "            derivatives = self.backward(X, Y, store)\n",
    " \n",
    "            for l in range(1, self.L + 1):\n",
    "                self.parameters[\"W\" + str(l)] = self.parameters[\"W\" + str(l)] - learning_rate * derivatives[\n",
    "                    \"dW\" + str(l)]\n",
    "                self.parameters[\"b\" + str(l)] = self.parameters[\"b\" + str(l)] - learning_rate * derivatives[\n",
    "                    \"db\" + str(l)]\n",
    " \n",
    "            if loop % 100 == 0:\n",
    "                print(\"Cost: \", cost, \"Train Accuracy:\", self.predict(X, Y))\n",
    " \n",
    "            if loop % 10 == 0:\n",
    "                self.costs.append(cost)\n",
    " \n",
    "    def predict(self, X, Y):\n",
    "        A, cache = self.forward(X)\n",
    "        y_hat = np.argmax(A, axis=0)\n",
    "        Y = np.argmax(Y, axis=1)\n",
    "        accuracy = (y_hat == Y).mean()\n",
    "        return accuracy * 100\n",
    " \n",
    "    def plot_cost(self):\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(len(self.costs)), self.costs)\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(\"cost\")\n",
    "        plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to load dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size is:  (300, 28, 28)\n",
      "Output size is:  (300,)\n",
      "Test size is:  (3, 28, 28)\n",
      "the first 10 sample of output is:  [4 1 1 1 4 1 8 4 1 1]\n"
     ]
    }
   ],
   "source": [
    "dataset= np.load(r'C:\\Users\\a335s717\\Desktop\\HW2\\mnist148.npz')\n",
    "new_dataset= dataset.files\n",
    "X = dataset['arr_0']\n",
    "Y = dataset['arr_1']\n",
    "Test = dataset['arr_2']\n",
    "\n",
    "print(\"Input size is: \", X.shape)\n",
    "print(\"Output size is: \", Y.shape)\n",
    "print(\"Test size is: \", Test.shape)\n",
    "print(\"the first 10 samples of output is: \", Y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is preparing the dataset. \n",
    "- the first thing is the size of the input which is (28*28) for each sample and we should change it to 784.\n",
    "- Next is the output value which is 1,4 or 8. this is categorical output and we have to use onehot encoding method to change the output.\n",
    "- Normalizing the input and output is the last thing that I want to do for preparing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train input size: (300, 784)\n",
      "Train Output size: (300, 3)\n",
      "Test Input size: (3, 784)\n",
      " the first 10 sample for output is:  [[0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "Input = []\n",
    "Output=[]\n",
    "count = np.zeros((10))\n",
    "w = np.random.random((28 * 28, 3))\n",
    "for x, y in zip(X,Y):\n",
    "    if y in [1, 4, 8]:\n",
    "        Input.append(x.reshape((28 * 28)) / 255)\n",
    "        count[y] += 1\n",
    "        \n",
    "        if y == [1]:\n",
    "            y = [1, 0, 0]\n",
    "        elif y == [4]:\n",
    "            y = [0, 1, 0]\n",
    "        elif y == [8]:\n",
    "            y = [0, 0, 1]   \n",
    "        Output.append(y)\n",
    "x_test=[]\n",
    "for x in Test : # reshape and normalize data\n",
    "    x_test.append(x.reshape((28 * 28)) / 255)\n",
    "\n",
    "samples = np.asarray(Input)\n",
    "labels = np.asarray(Output)\n",
    "test = np.asarray(x_test)\n",
    "\n",
    "X_train = samples\n",
    "Y_train = labels\n",
    "X_Test = test\n",
    "\n",
    "print(\"train input size: \" + str(X_train.shape))\n",
    "print(\"Train Output size: \"+ str(Y_train.shape))\n",
    "print(\"Test Input size: \" + str(X_Test.shape))\n",
    "print(\" the first 10 sample for output is: \", Y_train[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset is prepared and I want to use the functions of the Neural Network to create a NN for the dataset. At first I define the number of layers and nodes. Based on the question, the NN should be 3 layers which means 1 input layer, 2 hidden layer( 800 nodes in each) and 1 output layer( which is 3 nodes- because the out put is 3 base on one hot coding) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_nodes = [800 ,800, 3] # how many nodes for hidden layers and output layer is needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = ANN(layers_nodes)    # Create the Neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the Neural network is created and it consists of 784 nodes for input, 800 nodes for first hidden layer, 800 nodes for second hidden layer and 3 nodes for output. In next I want to train the Neural network but before that based on the question I hava to shuffle the dataset and select a batch of data instead of training the dataset with the all 300 samples. in hence, 3 parameters have to be defined. \n",
    "\n",
    "Epoch: \n",
    "iteration: \n",
    "Batchsize: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):  # number of epoch\n",
    "\n",
    "    # Shuffle dataset before going to trainig\n",
    "    s = np.arange(X_train.shape[0]) \n",
    "    np.random.shuffle(s)\n",
    "    X_train= X_train[s]\n",
    "    Y_train = Y_train[s]\n",
    "\n",
    "    for i in range(0, 300,30): # select a batch of data \n",
    "        XX_train = X_train[i:i+30]\n",
    "        YY_train = Y_train[i:i+30]\n",
    "        ann.train(XX_train, YY_train, learning_rate=0.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
